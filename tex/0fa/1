\documentclass{article}

\usepackage{jy}

\begin{document}

\section{Fourier Series}

\subsection{Introduction to Fourier Series}

This section provides an introduction to the Fourier series. We present three very powerful claims to motivate the developments of this section.

\begin{bclaim}
\begin{enumerate}
	\item Any periodic function $f(t)$ with period $T$ can be represented by the trigonometric series
$$f(t)=\frac{1}{2} a_0+\sum_{n=1}^\infty (a_n\cos n\w_0t+b_n\sin n\w_0t)$$ where $\w_0=\frac{2\pi}{T}$.
	\item There exists a formula to calculate the coefficients $a_0,a_n,$ and $b_n$ in the trigonometric series.
	\item It is possible to calculate the most accurate approximation of $f(t)$.
\end{enumerate}
\end{bclaim}

If these three claims are true, then any periodic function can be easily modelled on a computer.

\begin{defn} A periodic function is any function for which  \begin{equation} f(t) = f(t+T)
\end{equation} for all $t$. The smallest constant $T$ that satisfies (1.1) is called the period of the function.
\end{defn}

\begin{coro} If $f(t+T)=f(t)$, we have \begin{equation}
\int_\alpha^\beta f(t)\dd{t}=\int_{\alpha+T}^{\beta+T} f(t)\dd{t}
\end{equation} \begin{equation}
\int_0^T f(t)\dd{t}=\int_a^{a+T}f(t)\dd{t}
\end{equation} for any $\alpha,\beta,$ and $a$. \end{coro}

\begin{proof} To prove the first equality, we use the substitution $u=t+T$ on the LHS to obtain $\int_\alpha^\beta f(t)\dd{t}=\int_{\alpha+T}^{\beta+T} f(u-T)\dd{u}$, which is equal to the RHS. Next, by (2), we have $\int_a^0f(t)\dd{t}=\int_{a+T}^Tf(t)\dd{t}$, which means the RHS can be rewritten as $\int_a^{a+T}f(t)\dd{t}=\int_{a+T}^Tf(t)\dd{t}+\int_0^{a+T}f(t)\dd{t}$, which is equal to the LHS. \end{proof}

\begin{thm}[Fourier's Theorem] Any periodic function $f(t)$ with period $T$ can be represented by the trigonometric series
\begin{equation} f(t)=\frac{1}{2} a_0+\sum_{n=1}^\infty (a_n\cos n\w_0t+b_n\sin n\w_0t)
\end{equation} where $\w_0=\frac{2\pi}{T}$. \end{thm}

\begin{rem} We note that both $\sin$ and $\cos$ have a period of $2\pi$, and thus the constant $\w_0$ changes the period of both to $T$. \end{rem}

\begin{rem} The series in (4) can be rewritten as
\begin{equation}
f(t)=C_0+\sum_{n=1}^\infty C_n\cos(n\w_0t-\theta_n).
\end{equation} This is obtained by first setting $\frac12a_0=C_0$, then doing the following manipulations: \begin{equation} \begin{split}
(a_n\cos n\w_0t+b_n\sin n\w_0t) &=\sqrt{a_n^2+b_n^2}\left(\frac{a_n}{\sqrt{a_n^2+b_n^2}}\cos n\w_0t+\frac{b_n}{\sqrt{a_n^2+b_n^2}}\sin n\w_0t\right) \\ &= C_n(\cos\theta_n\cos n\w_0t+\sin\theta_n\sin n\w_0t) \\ &= C_n\cos(n\w_t-\theta_n)
\end{split} 
\end{equation} \end{rem}

\begin{defn} We now give names to several components of the trigonometric series.
\begin{enumerate}
	\item The terms $a_n,b_n$ are the Fourier coefficients of $f(t)$.
	\item The component of frequency $\w_n=n\w_0$ is called the $n$th harmonic of the periodic function.
	\item The first harmonic $C_1\cos(\w_0t\theta_1)$ is called the fundamental component, as it has the same period as $f(t)$.
	\item The constant $\w_0$ is called the fundamental angular frequency, and $f_0=\frac1T$ is the fundamental frequency.
	\item The coefficients $C_n$ and angles $\theta_n$ are the harmonic amplitudes and phase angles respectively.
\end{enumerate} \end{defn}

\begin{defn} A set of functions $\{\phi_k(t)\}$ is orthogonal on an interval $a<t<b$ if, for any two functions $\phi_m(t)$ and $\phi_n(t)$ in the set $\{\phi_k(t)\}$, the relation (7) holds.
\begin{equation}
\int_a^b \phi_m(t)\phi_n(t)\dd{t}= \begin{cases} 0 &\mbox{for } m\neq n \\ r_n & \mbox{for } m=n \end{cases}
\end{equation} \end{defn}

\begin{rem} Consider the following sinusoidal functions where $\w_0=\frac{2\pi}{T}$. They show that on the interval $-\frac{T}{2}<t<\frac T2$ the functions $\{1,\cos\w_0t,\cos2\w_0t,\ldots,\cos n\w_0t,\ldots,\sin\w_0t,\sin2\w_0t,\ldots,\sin n\w_0t,\ldots\}$ form an orthogonal set. \begin{equation} \int_{-\frac T2}^{\frac T2}\cos(m\w_0t)\dd{t}=0 \mbox{ for } m\neq0
\end{equation} \begin{equation} \int_{-\frac T2}^{\frac T2}\sin(m\w_0t)\dd{t}=0 \mbox{ for all } m
\end{equation} \begin{equation} \int_{-\frac T2}^{\frac T2}\cos(m\w_0t)\cos(n\w_0t)\dd{t} =\begin{cases} 0 &\mbox{for } m\neq n \\ \frac T2 & \mbox{for } m=n\neq0 \end{cases}
\end{equation} \begin{equation} \int_{-\frac T2}^{\frac T2}\sin(m\w_0t)\sin(n\w_0t)\dd{t} =\begin{cases} 0 &\mbox{for } m\neq n \\ \frac T2 & \mbox{for } m=n\neq0 \end{cases}
\end{equation} \begin{equation} \int_{-\frac T2}^{\frac T2}\sin(m\w_0t)\cos(n\w_0t)\dd{t} = 0 \mbox{ for all } m \mbox{ and } n
\end{equation} It is left to the reader to verify these calculations. \end{rem}

\begin{coro} We can take advantage of orthogonality to evaluate the Fourier coefficients of (4). \end{coro}
\begin{equation} a_n=\frac 2T\int_{-\frac T2}^{\frac T2}f(t)\cos(n\w_0t)\dd{t}
\end{equation} \begin{equation} b_n=\frac 2T\int_{-\frac T2}^{\frac T2}f(t)\sin(n\w_0t)\dd{t}
\end{equation} 
\begin{equation} \frac 12 a_0=\frac 1T \int_{-\frac T2}^{\frac T2}f(t)\dd{t}
\end{equation}

\begin{proof}
The proof techniques for (13) and (14) are similar, and involve expanding $f(t)$. Finally, (15) follows directly from setting $n=0$ in (13). To prove (13), we begin by expanding the RHS.
\begin{equation} \begin{split}
\frac 2T\int_{-\frac T2}^{\frac T2}f(t)\cos(n\w_0t)\dd{t} &= \frac{2}{T}\int_{-\frac T2}^{\frac T2}\left(\frac{1}{2} a_0+\sum_{i=1}^\infty (a_i\cos i\w_0t+b_i\sin i\w_0t)\right)\cos(n\w_0t) \dd{t} \\ &= \frac{a_0}{T}\int_{-\frac{T}{2}}^{\frac T2}\cos(n\w_0t)\dd{t}+\frac{2}{T}\int_{-\frac T2}^{\frac T2}\left(\sum_{i=1}^\infty (a_i\cos i\w_0t+b_i\sin i\w_0t)\right)\cos(n\w_0t) \dd{t} \\ &= \frac{2}{T}\left(\sum_{i=1}^\infty a_i\int_{-\frac T2}^{\frac T2}\cos(i\w_0t)\cos(n\w_0t)\dd{t}+\sum_{i=1}^\infty b_i\int_{-\frac T2}^{\frac T2}\sin(i\w_0t)\cos(n\w_0t)\dd{t}\right) \\ &= \frac{2}{T}(a_n\frac{T}{2}) \\ &= a_n \qedhere \end{split}
\end{equation} We also note that $\frac{a_0}{2}$ is the average value of $f(t)$ over a period.
\end{proof}

\begin{rem} Finding the Fourier coefficients of a series is useful in finding the Fourier series for periodic functions. \end{rem}

\begin{eg} Find the Fourier series for the function $f(t)$ defined by $$f(t)=\begin{cases} -1 & -\frac T2<t<0 \\ 1 & 0<t<\frac T2 \end{cases}$$ and $f(t+T)=f(t)$. \end{eg}

\begin{soln} First, we calculate $a_n$ using (13), and realize that $a_n=0$. Calculating $b_n$, we obtain $b_n=\frac{2}{n\pi}(1-\cos n\pi)$. We then note that $\cos n\pi=(-1)^n$, and therefore obtain \begin{equation*} b_n=\begin{cases} 0 & n \mbox{ even} \\ \frac{4}{n\pi} & n \mbox{ odd.} \end{cases}
\end{equation*} Hence, $f(t)=\frac{4}{\pi}\left(\sin\w_0t+\frac{1}{3}\sin3\w_0t+\frac{1}{5}\sin5\w_0t+\ldots\right).$
\end{soln}

Calculating approximations of the Fourier series of functions is often more efficient computing-wise than calculating stupid numbers of terms. The finite Fourier series \begin{equation} S_k(t)=\frac{a_0}{2}+\sum_{n=1}^k(a_n\cos n\w_0t+b_n\sin n\w_0t)
\end{equation} is the sum of the first $(2k+1)$ terms of a Fourier series that represents $f(t)$ on $-\frac T2<t<\frac T2$. The function $\veps_k(t)$ is the error between $f(t)$ and $S_k(t)$, and is simply $$\veps_k(t)=f(t)-S_k(t).$$

\begin{defn} The mean-square error $E_k$ is defined as \begin{equation} E_k=\frac 1T\int_{-\frac T2}^{\frac T2}[\veps_k(t)]^2\dd{t}.
\end{equation}
\end{defn}

\begin{claim} \begin{equation} E_k=\frac 1T\int_{-\frac T2}^{\frac T2}[f(t)]^2\dd{t}-\frac{a_0^2}{4}-\frac12\sum_{n=1}^k(a_n^2+b_n^2).
\end{equation} \end{claim}

\begin{proof} This proof is very long and tedious, so we rewrite certain parts first. Let $\alpha:=\frac 1T\int_{-\frac T2}^{\frac T2}[f(t)]^2\dd{t}$ and let $p:=a_n\cos(n\w_0t)+b_n\sin(n\w_0t)$. We start from the definition of $E_k$ and expand from there.
\begin{align*}
E_k &= \frac 1T\int_{-\frac T2}^{\frac T2}[\veps_k(t)]^2\dd{t} \\ &= \frac1T\int_{-\frac T2}^{\frac T2}[f(t)]^2-2f(t)S_k(t)+[S_k(t)]^2\dd{t} \\ &= \alpha-\left(\frac2T\int_{-\frac T2}^{\frac T2}f(t)S_k(t)\dd{t}\right)+\left(\frac1T\int_{-\frac T2}^{\frac T2}[S_k(t)]^2\dd{t}\right)
\end{align*}
Now, we work on simplifying the second term. Several of the identities are heavily abused here, namely (13)-(15).
\begin{align*}
\frac2T\int_{-\frac T2}^{\frac T2}f(t)S_k(t)\dd{t} &= \frac2T\int_{-\frac T2}^{\frac T2}f(t)\left(\frac{a_0}{2}+\sum_{n=1}^kp\right)\dd{t} \\ &= \frac{a_0}{T}\int_{-\frac T2}^{\frac T2}f(t)\dd{t}+\frac2T\int_{-\frac T2}^{\frac T2}f(t)\left(\sum_{n=1}^kp\right)\dd{t} \\ &= \frac{a_0^2}{2}+\sum_{n=1}^ka_n\int_{-\frac T2}^{\frac T2}f(t)\cos(n\w_0t)\dd{t}+\sum_{n=1}^kb_n\int_{-\frac T2}^{\frac T2}f(t)\sin(n\w_0t)\dd{t} \\ &= \frac{a_0^2}{2}+\sum_{n=1}^ka_n^2+\sum_{n=1}^kb_n^2 \\ &= \frac{a_0^2}{2}+\sum_{n=1}^k\left(a_n^2+b_n^2\right)
\end{align*}
Next, we simplify the third term, abusing (8)-(12).
\begin{align*}
\frac1T\int_{-\frac T2}^{\frac T2}[S_k(t)]^2\dd{t} &= \frac1T\int_{-\frac T2}^{\frac T2}\left(\frac{a_0}{2}+\sum_{n=1}^kp\right)\left(\frac{a_0}{2}+\sum_{n=1}^kp\right)\dd{t} \\ &= \frac1T\int_{-\frac T2}^{\frac T2}\frac{a_0^2}{4}+a_0\sum_{n=1}^kp+\left(\sum_{n=1}^kp\right)^2\dd{t} \\ &= \frac{a_0^2}{4}+\frac{a_0}{T}\int_{-\frac T2}^{\frac T2}\sum_{n=1}^kp\dd{t}+\frac1T\int_{-\frac T2}^{\frac T2}\left(\sum_{n=1}^kp\right)^2\dd{t} \\ &= \frac{a_0^2}{4}+\frac1T\int_{-\frac T2}^{\frac T2}\left(\sum_{n=1}^kp\right)^2\dd{t} \\ &= \frac{a_0^2}{4}+\frac1T\int_{-\frac T2}^{\frac T2}\sum_{n=1}^ka_n^2\cos^2(n\w_0t)+\sum_{n=1}^kb_n^2\sin^2(n\w_0t)+R\dd{t} \\ &= \frac{a_0^2}{4}+\frac12\sum_{n=1}^k(a_n^2+b_n^2)
\end{align*}
Putting all three terms back together, we obtain
\begin{align*}
E_k &= \frac 1T\int_{-\frac T2}^{\frac T2}[f(t)]^2\dd{t}-\frac{a_0^2}{4}-\frac12\sum_{n=1}^k(a_n^2+b_n^2).
\end{align*}
The $R$ in the second last line of the working is the remainder after expanding the square of the summation, and its integral is $0$, as noted by (12).
\end{proof}

\begin{claim} The approximation of $f(t)$ by the finite Fourier series $S_k(t)$ has the least mean-square error property, i.e. $S_k(t)$ is the most accurate approximation of $f(t)$. \end{claim}

\begin{proof} The mean-square error $E_k$ can be considered as a function of $a_0$, $a_n$, and $b_n$. To minimize $E_k$, its partial derivatives with respect to all three variables must be zero. Therefore, if we are able to show that $\pdv{E_k}{a_0}=\pdv{E_k}{a_n}=\pdv{E_k}{b_n}=0$, we are done. After doing some differentiation and rearranging of terms, we are done. \end{proof}

\begin{lemma}[Parseval's Identity] If $a_0$, $a_n$, and $b_n$ are the coefficients in the Fourier expansion of a periodic function $f(t)$ with period $T$, then \begin{equation} \frac1T\int_{-\frac T2}^{\frac T2}[f(t)]^2\dd{t}=\frac{a_0^2}{4}+\frac12\sum_{n=1}^\infty(a_n^2+b_n^2)
\end{equation}
\end{lemma}

\begin{proof}
From (17), we know that $E_k$ is non-negative, and from (18) we know that \begin{equation} E_{k+1}=E_k-\frac12\left(a_{k+1}^2+b_{k+1}^2\right)
\end{equation}
Thus, the sequence $\{E_k\}$ is decreasing, and therefore converges as it is also non-negative. In other words, $\lim_{k\to\infty}E_k=0$, and we obtain (19) from (18).
\end{proof}

\end{document}
